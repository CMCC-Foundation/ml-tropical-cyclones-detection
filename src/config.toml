[dirs]
main = '../'
data = '../data/'
model = '../backup/'
experiments = '../experiments/'
dataset = '../data/tfrecord/trainval/'
scaler = '../data/scaler/'
scaler_filename = 'x_scaler.dump'

[run]
name = 'vgg_test'
seed = 42

[data]
patch_size = 40
drivers = ['fg10', 'msl', 't_500', 't_300']
targets = ['patch_cyclone']
drivers_shape = [40, 40]
targets_shape = [2,]
patch_type = 'nearest'
force_scaler_compute = true

[model]
network = "lb.models.VGG_V1(patch_size=40, channels=[6,2], initializer=tf.random_normal_initializer(0., 0.02), activation='relu', regularizer=None, kernel_size=3)"
loss = "tf.keras.losses.MeanAbsoluteError(name='mae')"
optimizer = "tf.keras.optimizers.Adam(learning_rate=0.0001)"
metrics = [
    "tf.keras.metrics.MeanSquaredError(name='mse')"
]
callbacks = [
    "lb.callbacks.ProcessBenchmark(BENCHMARK_HISTORY_CSV)",
    "tf.keras.callbacks.CSVLogger(LOSS_METRICS_HISTORY_CSV)",
    "tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100, min_delta=0.0001, restore_best_weights=True, verbose=1, mode='min')",
    "tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT_FNAME, save_best_only=True, monitor='val_loss', mode='min', save_weights_only=False, verbose=1)",
]

[training]
epochs = 500
batch_size = 8192
shuffle_buffer = 32768
label_no_cyclone = -1.0
only_tcs = true

[training.augmentation]
left_right = "lb.aug.coo_left_right"
up_down = "lb.aug.coo_up_down"
rot180 = "lb.aug.coo_rot180"
